{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GREEN FUTURE ..","metadata":{}},{"cell_type":"markdown","source":"### let's Start ..","metadata":{}},{"cell_type":"markdown","source":"### Import libraries : ","metadata":{}},{"cell_type":"code","source":"#!pip install -q efficientnet\n#!pip install keras\n#!pip install tensorflow","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport scipy as sp\n\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n#import efficientnet.tfkeras as efn\nfrom sklearn import metrics\n\n\nfrom IPython.display import SVG\n#from tensorflow.keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.utils import plot_model\n\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import DenseNet121\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T11:09:44.427204Z","iopub.execute_input":"2021-12-07T11:09:44.427877Z","iopub.status.idle":"2021-12-07T11:09:54.501934Z","shell.execute_reply.started":"2021-12-07T11:09:44.427758Z","shell.execute_reply":"2021-12-07T11:09:54.500652Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load Data :","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nSAMPLE_LEN = 100\nIMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\nTEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\nTRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\nSUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n\nsub = pd.read_csv(SUB_PATH)\ntest_data = pd.read_csv(TEST_PATH)\ntrain_data = pd.read_csv(TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:09:59.358191Z","iopub.execute_input":"2021-12-07T11:09:59.358491Z","iopub.status.idle":"2021-12-07T11:09:59.410161Z","shell.execute_reply.started":"2021-12-07T11:09:59.358459Z","shell.execute_reply":"2021-12-07T11:09:59.408975Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:10:01.900667Z","iopub.execute_input":"2021-12-07T11:10:01.901306Z","iopub.status.idle":"2021-12-07T11:10:01.924868Z","shell.execute_reply.started":"2021-12-07T11:10:01.901272Z","shell.execute_reply":"2021-12-07T11:10:01.924247Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:10:06.577622Z","iopub.execute_input":"2021-12-07T11:10:06.578049Z","iopub.status.idle":"2021-12-07T11:10:06.590753Z","shell.execute_reply.started":"2021-12-07T11:10:06.578002Z","shell.execute_reply":"2021-12-07T11:10:06.589984Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Load sample images : ","metadata":{}},{"cell_type":"code","source":"def load_image(image_id):\n    file_path = image_id + \".jpg\"\n    image = cv2.imread(IMAGE_PATH + file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ntrain_images = train_data[\"image_id\"][:SAMPLE_LEN].progress_apply(load_image)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:10:24.783248Z","iopub.execute_input":"2021-12-07T11:10:24.783575Z","iopub.status.idle":"2021-12-07T11:10:29.811116Z","shell.execute_reply.started":"2021-12-07T11:10:24.783541Z","shell.execute_reply":"2021-12-07T11:10:29.810120Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Visualize leaves :","metadata":{}},{"cell_type":"code","source":"#Sample image :\n\nfig = px.imshow(cv2.resize(train_images[0], (205, 136)))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:10:38.603006Z","iopub.execute_input":"2021-12-07T11:10:38.603804Z","iopub.status.idle":"2021-12-07T11:10:39.593801Z","shell.execute_reply.started":"2021-12-07T11:10:38.603759Z","shell.execute_reply":"2021-12-07T11:10:39.592954Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"When clicking on the image you can see the RGB values.\n\nThe green parts of the image have very low blue values, the brown parts have high blue values.\n\nThis suggests the green \"healthy\" parts of the image have \"low\" blue values.\n\nWhere \"unhealthy\" parts are more likely to have high blue values.\n\nThis might suggest that the blue channel may be the key to detecting diseases in plants.","metadata":{}},{"cell_type":"markdown","source":"### The data are labeled, let's see it..","metadata":{}},{"cell_type":"markdown","source":"## Visualize Targets :","metadata":{}},{"cell_type":"code","source":"def visualize_leaves(cond=[0, 0, 0, 0], cond_cols=[\"healthy\"], is_cond=True):\n    if not is_cond:\n        cols, rows = 3, min([3, len(train_images)//3])\n        fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(30, rows*20/3))\n        for col in range(cols):\n            for row in range(rows):\n                ax[row, col].imshow(train_images.loc[train_images.index[-row*3-col-1]])\n        return None\n        \n    cond_0 = \"healthy == {}\".format(cond[0])\n    cond_1 = \"scab == {}\".format(cond[1])\n    cond_2 = \"rust == {}\".format(cond[2])\n    cond_3 = \"multiple_diseases == {}\".format(cond[3])\n    \n    cond_list = []\n    for col in cond_cols:\n        if col == \"healthy\":\n            cond_list.append(cond_0)\n        if col == \"scab\":\n            cond_list.append(cond_1)\n        if col == \"rust\":\n            cond_list.append(cond_2)\n        if col == \"multiple_diseases\":\n            cond_list.append(cond_3)\n    \n    data = train_data.loc[:100]\n    for cond in cond_list:\n        data = data.query(cond)\n        \n    images = train_images.loc[list(data.index)]\n    cols, rows = 3, min([3, len(images)//3])\n    \n    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(30, rows*20/3))\n    for col in range(cols):\n        for row in range(rows):\n            ax[row, col].imshow(images.loc[images.index[row*3+col]])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:10:46.631384Z","iopub.execute_input":"2021-12-07T11:10:46.631740Z","iopub.status.idle":"2021-12-07T11:10:46.647263Z","shell.execute_reply.started":"2021-12-07T11:10:46.631704Z","shell.execute_reply":"2021-12-07T11:10:46.646479Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### 1- Healthy leaves","metadata":{}},{"cell_type":"code","source":"#visualize_leaves(cond=[1, 0, 0, 0], cond_cols=[\"healthy\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-06T19:51:53.636706Z","iopub.execute_input":"2021-12-06T19:51:53.637028Z","iopub.status.idle":"2021-12-06T19:51:53.64133Z","shell.execute_reply.started":"2021-12-06T19:51:53.636995Z","shell.execute_reply":"2021-12-06T19:51:53.640393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the healthy leaves are completely green, do not have any brown/yellow spots or scars. Healthy leaves do not have scab or rust.","metadata":{}},{"cell_type":"markdown","source":"### 2- Leaves with scab ","metadata":{}},{"cell_type":"code","source":"visualize_leaves(cond=[0, 1, 0, 0], cond_cols=[\"scab\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:12:45.989161Z","iopub.execute_input":"2021-12-07T11:12:45.989476Z","iopub.status.idle":"2021-12-07T11:12:51.612567Z","shell.execute_reply.started":"2021-12-07T11:12:45.989445Z","shell.execute_reply":"2021-12-07T11:12:51.611865Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We can see that leaves with \"scab\" have large brown marks and stains across the leaf.\n\nScab is \"any of various plant diseases caused by fungi or bacteria and resulting in crustlike spots on fruit, leaves, or roots. The spots caused by such a disease\". Once diagnosed, scab can be treated using chemical or non-chemical methods.","metadata":{}},{"cell_type":"markdown","source":"### 3- Leaves with rust","metadata":{}},{"cell_type":"code","source":"visualize_leaves(cond=[0, 0, 1, 0], cond_cols=[\"rust\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:00.023928Z","iopub.execute_input":"2021-12-07T11:13:00.024300Z","iopub.status.idle":"2021-12-07T11:13:04.977177Z","shell.execute_reply.started":"2021-12-07T11:13:00.024265Z","shell.execute_reply":"2021-12-07T11:13:04.975988Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"We can see that leaves with \"rust\" have several brownish-yellow spots across the leaf.\n\nRust is \"a disease, especially of cereals and other grasses, characterized by rust-colored pustules of spores on the affected leaf blades and sheaths and caused by any of several rust fungi\". The yellow spots are a sign of infection by a special type of fungi called \"rust fungi\". Rust can also be treated with several chemical and non-chemical methods once diagnosed.","metadata":{}},{"cell_type":"markdown","source":"### 4- Leaves with multiple diseases ","metadata":{}},{"cell_type":"code","source":"visualize_leaves(cond=[0, 0, 0, 1], cond_cols=[\"multiple_diseases\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:11.467868Z","iopub.execute_input":"2021-12-07T11:13:11.468174Z","iopub.status.idle":"2021-12-07T11:13:14.928671Z","shell.execute_reply.started":"2021-12-07T11:13:11.468145Z","shell.execute_reply":"2021-12-07T11:13:14.927682Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"We can see that the leaves show symptoms of several diseases, including brown marks and yellow spots. These plants have more than one of the above-described diseases.","metadata":{}},{"cell_type":"markdown","source":"### Parallel Plot ","metadata":{}},{"cell_type":"code","source":" fig = px.parallel_categories(train_data[[\"healthy\", \"scab\", \"rust\", \"multiple_diseases\"]], color=\"healthy\", color_continuous_scale=\"sunset\",\\\n                             title=\"Parallel categories plot of targets\")\nfig","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:22.710535Z","iopub.execute_input":"2021-12-07T11:13:22.710968Z","iopub.status.idle":"2021-12-07T11:13:22.846582Z","shell.execute_reply.started":"2021-12-07T11:13:22.710923Z","shell.execute_reply":"2021-12-07T11:13:22.845599Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We can see the relationship between all four categories.\n\nIt is impossible for a healthy leaf (healthy == 1) to have scab, rust, or multiple diseases.\n\nAlso, every unhealthy leaf has either scab, rust, or multiple diseases. The frequency of each combination can be seen by hovering over the plot.","metadata":{}},{"cell_type":"markdown","source":"### Pie Chart","metadata":{}},{"cell_type":"code","source":" fig = go.Figure([go.Pie(labels=train_data.columns[1:],\n           values=train_data.iloc[:, 1:].sum().values)])\nfig.update_layout(title_text=\"Pie chart of targets\", template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:27.596447Z","iopub.execute_input":"2021-12-07T11:13:27.596765Z","iopub.status.idle":"2021-12-07T11:13:27.724872Z","shell.execute_reply.started":"2021-12-07T11:13:27.596731Z","shell.execute_reply":"2021-12-07T11:13:27.723950Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"We can see that most leaves in the dataset are unhealthy (71.7%). Only 5% of plants have multiple diseases, and \"rust\" and \"scab\" occupy approximately one-third of the pie each.","metadata":{}},{"cell_type":"markdown","source":"## Image processing and augmentation : \n\nData augmentation: techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.","metadata":{}},{"cell_type":"markdown","source":"### 1- Canny edge detection : ","metadata":{}},{"cell_type":"code","source":"def edge_and_cut(img):\n    emb_img = img.copy()\n    edges = cv2.Canny(img, 100, 200)\n    edge_coors = []\n    for i in range(edges.shape[0]):\n        for j in range(edges.shape[1]):\n            if edges[i][j] != 0:\n                edge_coors.append((i, j))\n    \n    row_min = edge_coors[np.argsort([coor[0] for coor in edge_coors])[0]][0]\n    row_max = edge_coors[np.argsort([coor[0] for coor in edge_coors])[-1]][0]\n    col_min = edge_coors[np.argsort([coor[1] for coor in edge_coors])[0]][1]\n    col_max = edge_coors[np.argsort([coor[1] for coor in edge_coors])[-1]][1]\n    new_img = img[row_min:row_max, col_min:col_max]\n    \n    emb_img[row_min-10:row_min+10, col_min:col_max] = [255, 0, 0]\n    emb_img[row_max-10:row_max+10, col_min:col_max] = [255, 0, 0]\n    emb_img[row_min:row_max, col_min-10:col_min+10] = [255, 0, 0]\n    emb_img[row_min:row_max, col_max-10:col_max+10] = [255, 0, 0]\n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))\n    ax[0].imshow(img, cmap='gray')\n    ax[0].set_title('Original Image', fontsize=24)\n    ax[1].imshow(edges, cmap='gray')\n    ax[1].set_title('Canny Edges', fontsize=24)\n    ax[2].imshow(emb_img, cmap='gray')\n    ax[2].set_title('Bounding Box', fontsize=24)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:33.073178Z","iopub.execute_input":"2021-12-07T11:13:33.073508Z","iopub.status.idle":"2021-12-07T11:13:33.091117Z","shell.execute_reply.started":"2021-12-07T11:13:33.073475Z","shell.execute_reply":"2021-12-07T11:13:33.089890Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"edge_and_cut(train_images[3])\nedge_and_cut(train_images[4])\nedge_and_cut(train_images[5])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:13:59.602076Z","iopub.execute_input":"2021-12-07T11:13:59.602442Z","iopub.status.idle":"2021-12-07T11:14:32.648805Z","shell.execute_reply.started":"2021-12-07T11:13:59.602399Z","shell.execute_reply":"2021-12-07T11:14:32.648070Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### 2- Flipping : ","metadata":{}},{"cell_type":"markdown","source":"flip images horizontally and vertically. Some frameworks do not provide function for vertical flips. But, a vertical flip is equivalent to rotating an image by 180 degrees and then performing a horizontal flip. Below are examples for images that are flipped.","metadata":{}},{"cell_type":"code","source":"def invert(img):\n    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))\n    ax[0].imshow(img)\n    ax[0].set_title('Original Image', fontsize=24)\n    ax[1].imshow(cv2.flip(img, 0))\n    ax[1].set_title('Vertical Flip', fontsize=24)\n    ax[2].imshow(cv2.flip(img, 1))\n    ax[2].set_title('Horizontal Flip', fontsize=24)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:14:47.559441Z","iopub.execute_input":"2021-12-07T11:14:47.559974Z","iopub.status.idle":"2021-12-07T11:14:47.568251Z","shell.execute_reply.started":"2021-12-07T11:14:47.559932Z","shell.execute_reply":"2021-12-07T11:14:47.567294Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"invert(train_images[3])\ninvert(train_images[4])\ninvert(train_images[5])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:14:50.115409Z","iopub.execute_input":"2021-12-07T11:14:50.115706Z","iopub.status.idle":"2021-12-07T11:14:55.304890Z","shell.execute_reply.started":"2021-12-07T11:14:50.115676Z","shell.execute_reply":"2021-12-07T11:14:55.304173Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 3- Convolution :","metadata":{}},{"cell_type":"code","source":"def conv(img):\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 20))\n    kernel = np.ones((7, 7), np.float32)/25\n    conv = cv2.filter2D(img, -1, kernel)\n    ax[0].imshow(img)\n    ax[0].set_title('Original Image', fontsize=24)\n    ax[1].imshow(conv)\n    ax[1].set_title('Convolved Image', fontsize=24)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:15:02.467754Z","iopub.execute_input":"2021-12-07T11:15:02.468277Z","iopub.status.idle":"2021-12-07T11:15:02.474705Z","shell.execute_reply.started":"2021-12-07T11:15:02.468247Z","shell.execute_reply":"2021-12-07T11:15:02.474026Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"conv(train_images[3])\nconv(train_images[4])\nconv(train_images[5])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:16:12.953569Z","iopub.execute_input":"2021-12-07T11:16:12.954010Z","iopub.status.idle":"2021-12-07T11:16:16.904425Z","shell.execute_reply.started":"2021-12-07T11:16:12.953977Z","shell.execute_reply":"2021-12-07T11:16:16.903495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### 4- Blurring :","metadata":{}},{"cell_type":"code","source":"def blur(img):\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 20))\n    ax[0].imshow(img)\n    ax[0].set_title('Original Image', fontsize=24)\n    ax[1].imshow(cv2.blur(img, (100, 100)))\n    ax[1].set_title('Blurred Image', fontsize=24)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:16:22.483677Z","iopub.execute_input":"2021-12-07T11:16:22.483982Z","iopub.status.idle":"2021-12-07T11:16:22.491076Z","shell.execute_reply.started":"2021-12-07T11:16:22.483953Z","shell.execute_reply":"2021-12-07T11:16:22.489650Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"blur(train_images[3])\nblur(train_images[4])\nblur(train_images[5])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:16:31.271949Z","iopub.execute_input":"2021-12-07T11:16:31.272999Z","iopub.status.idle":"2021-12-07T11:16:34.915050Z","shell.execute_reply.started":"2021-12-07T11:16:31.272938Z","shell.execute_reply":"2021-12-07T11:16:34.914147Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Modeling :","metadata":{}},{"cell_type":"markdown","source":"### Setup TPU :","metadata":{}},{"cell_type":"markdown","source":"Setup TPU Config:\n\nAUTO : Automated machine learning\n\nTPU : Tensor Processing Units","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:16:41.554345Z","iopub.execute_input":"2021-12-07T11:16:41.554623Z","iopub.status.idle":"2021-12-07T11:16:48.125436Z","shell.execute_reply.started":"2021-12-07T11:16:41.554596Z","shell.execute_reply":"2021-12-07T11:16:48.124345Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Load labels and paths :","metadata":{}},{"cell_type":"code","source":"def format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'\n\ntest_paths = test_data.image_id.apply(format_path).values\ntrain_paths = train_data.image_id.apply(format_path).values\n\ntrain_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\ntrain_paths, valid_paths, train_labels, valid_labels =\\\ntrain_test_split(train_paths, train_labels, test_size=0.15, random_state=2020)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:16:52.145068Z","iopub.execute_input":"2021-12-07T11:16:52.145413Z","iopub.status.idle":"2021-12-07T11:16:52.164439Z","shell.execute_reply.started":"2021-12-07T11:16:52.145382Z","shell.execute_reply":"2021-12-07T11:16:52.163616Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Decode image & Data augment","metadata":{}},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:17:12.484917Z","iopub.execute_input":"2021-12-07T11:17:12.485484Z","iopub.status.idle":"2021-12-07T11:17:12.493508Z","shell.execute_reply.started":"2021-12-07T11:17:12.485448Z","shell.execute_reply":"2021-12-07T11:17:12.492289Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Create Dataset : ","metadata":{}},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:17:46.780065Z","iopub.execute_input":"2021-12-07T11:17:46.780830Z","iopub.status.idle":"2021-12-07T11:17:46.868552Z","shell.execute_reply.started":"2021-12-07T11:17:46.780777Z","shell.execute_reply":"2021-12-07T11:17:46.867595Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions :","metadata":{}},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:17:52.269902Z","iopub.execute_input":"2021-12-07T11:17:52.270742Z","iopub.status.idle":"2021-12-07T11:17:52.278400Z","shell.execute_reply.started":"2021-12-07T11:17:52.270667Z","shell.execute_reply":"2021-12-07T11:17:52.277223Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Define hyperparameters and callbacks :","metadata":{}},{"cell_type":"code","source":"lrfn = build_lrfn()\nSTEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:18:00.341646Z","iopub.execute_input":"2021-12-07T11:18:00.342171Z","iopub.status.idle":"2021-12-07T11:18:00.347548Z","shell.execute_reply.started":"2021-12-07T11:18:00.342130Z","shell.execute_reply":"2021-12-07T11:18:00.346589Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### DenseNet : ","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([DenseNet121(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:18:02.900155Z","iopub.execute_input":"2021-12-07T11:18:02.900442Z","iopub.status.idle":"2021-12-07T11:18:25.807700Z","shell.execute_reply.started":"2021-12-07T11:18:02.900413Z","shell.execute_reply":"2021-12-07T11:18:25.806754Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Train model : ","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:18:31.750524Z","iopub.execute_input":"2021-12-07T11:18:31.750835Z","iopub.status.idle":"2021-12-07T11:31:53.313956Z","shell.execute_reply.started":"2021-12-07T11:18:31.750782Z","shell.execute_reply":"2021-12-07T11:31:53.312929Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Visualize results : ","metadata":{}},{"cell_type":"code","source":"def display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:41:53.750565Z","iopub.execute_input":"2021-12-07T11:41:53.751317Z","iopub.status.idle":"2021-12-07T11:41:53.760361Z","shell.execute_reply.started":"2021-12-07T11:41:53.751279Z","shell.execute_reply":"2021-12-07T11:41:53.759510Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Scatter plots\ndisplay_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:41:59.524626Z","iopub.execute_input":"2021-12-07T11:41:59.525360Z","iopub.status.idle":"2021-12-07T11:41:59.593173Z","shell.execute_reply.started":"2021-12-07T11:41:59.525321Z","shell.execute_reply":"2021-12-07T11:41:59.592277Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Sample predictions : ","metadata":{}},{"cell_type":"code","source":"def process(img):\n    return cv2.resize(img/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\nfig = make_subplots(rows=4, cols=2)\npreds = predict(train_images[2])\n\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Scab\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Multiple diseases\"\n\ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Healthy\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[2], (205, 136))), row=1, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=1, col=2)\nfig.update_layout(height=1200, width=800, title_text=\"DenseNet Predictions\", showlegend=False)\n\npreds = predict(train_images[0])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Multiple diseases\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[0], (205, 136))), row=2, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=2, col=2)\n\npreds = predict(train_images[3])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Rust\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[3], (205, 136))), row=3, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=3, col=2)\n\npreds = predict(train_images[1])\ncolors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0], \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\nif list.index(preds.tolist(), max(preds)) == 0:\n    pred = \"Healthy\"\nif list.index(preds.tolist(), max(preds)) == 1:\n    pred = \"Multiple diseases\"\nif list.index(preds.tolist(), max(preds)) == 2:\n    pred = \"Rust\"\nif list.index(preds.tolist(), max(preds)) == 3:\n    pred = \"Scab\"\n    \ncolors[pred] = px.colors.qualitative.Plotly[1]\ncolors[\"Scab\"] = \"seagreen\"\ncolors = [colors[val] for val in colors.keys()]\nfig.add_trace(go.Image(z=cv2.resize(train_images[1], (205, 136))), row=4, col=1)\nfig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], y=preds, marker=dict(color=colors)), row=4, col=2)\n\nfig.update_layout(template=\"plotly_white\")","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:42:05.622547Z","iopub.execute_input":"2021-12-07T11:42:05.622842Z","iopub.status.idle":"2021-12-07T11:42:13.659058Z","shell.execute_reply.started":"2021-12-07T11:42:05.622801Z","shell.execute_reply":"2021-12-07T11:42:13.658124Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"probs_dnn = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_dnn\nsub.to_csv('submission_dnn.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T11:42:31.140627Z","iopub.execute_input":"2021-12-07T11:42:31.141220Z","iopub.status.idle":"2021-12-07T11:43:49.895852Z","shell.execute_reply.started":"2021-12-07T11:42:31.141180Z","shell.execute_reply":"2021-12-07T11:43:49.894893Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"########################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}